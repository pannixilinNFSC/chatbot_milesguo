{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8cfdfad-283b-4f36-9479-f5795d1a5227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import re\n",
    "import numpy as np\n",
    "import faiss\n",
    "import pickle\n",
    "import gzip\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import openai\n",
    "from openai import OpenAI # API v2.0\n",
    "#from openai.embeddings_utils import get_embedding, get_embeddings # before v1.2\n",
    "\n",
    "with open(\"openai_key.txt\", \"r\") as f:\n",
    "    openai_key = f.read().strip()\n",
    "    openai_client = OpenAI(api_key=openai_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27204161-33ff-467f-b6cc-7b315fa17aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义函数\n",
    "\n",
    "def crawler_page_urls():\n",
    "    \"\"\"# 爬取所有2866个连接 \"\"\"\n",
    "    urls0 = [f\"https://gwins.org/cn/milesguo/list_2_{i}.html\" for i in range(1,73)]\n",
    "    urls1 = []\n",
    "    for url in tqdm(urls0):\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:    \n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            html_doc = soup.get_text() \n",
    "            link_string = '\\n'.join([str(link) for link in soup.find_all('a')])\n",
    "            pattern = r\"/cn/milesguo/[\\w/]+\\.html\"\n",
    "            matches = re.findall(pattern, link_string)\n",
    "            urls2 = [f\"https://gwins.org{x}\" for x in matches]\n",
    "            urls1 += urls2\n",
    "            print(len(urls1))\n",
    "        else:\n",
    "            print(f\"无法获取页面{url}，HTTP状态码：{response.status_code}\")\n",
    "    return urls1\n",
    "\n",
    "def download_documents():\n",
    "    \"\"\"# 爬取所有2866个文章，并保存为文档\"\"\" \n",
    "    urls1 = crawler_page_urls() # 爬取所有2866个连接\n",
    "    out_folder = \"./txts\"\n",
    "    if not os.path.isdir(out_folder): \n",
    "        os.mkdir(\"./txts\")\n",
    "    for url in tqdm(urls1):\n",
    "        pattern = r'\\d+'\n",
    "        id = re.search(pattern, url).group() # 获取网页编号\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:    \n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        else:\n",
    "            print(f\"无法获取页面{url}，HTTP状态码：{response.status_code}\")\n",
    "            continue\n",
    "        html_doc = soup.get_text()  # 获取网页中的纯文本内容\n",
    "        html_doc = re.sub(r'\\s+', ' ', html_doc) # 去掉多余空格\n",
    "        \n",
    "        file_path = os.path.join(out_folder, f\"{id}.txt\")\n",
    "        with open(file_path, \"w\") as f:\n",
    "            f.write(html_doc) # 保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cbe45e3a-476f-4ea0-adc7-6f3af655701a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_titles(input_dir=\"./txts/\", out_file=\"titles.json\"):\n",
    "    \"\"\"提取每个文档的标题\"\"\"\n",
    "    files = [os.path.join(input_dir, x) for x in os.listdir(input_dir)]\n",
    "    dict1 = dict()\n",
    "    for in_file in tqdm(files):\n",
    "        id = os.path.basename(in_file).split(\".\")[0]\n",
    "        with open(in_file, \"r\") as f:\n",
    "            txt = f.read()\n",
    "        pattern1 = r'^(.*?)首页'\n",
    "        match = re.match(pattern1, txt)\n",
    "        if match: \n",
    "            title = match.group(1)\n",
    "            title = title.replace(\"\\n\", \" \")\n",
    "        else:\n",
    "            title = \"unknown title\"\n",
    "        dict1[id] = title\n",
    "        #print(title)\n",
    "    with open(out_file, \"w\") as f:\n",
    "        json.dump(dict1, f)\n",
    "\n",
    "def load_titles(file=\"title.json\"):\n",
    "    with open(file, \"r\") as f:\n",
    "        dict1 = json.load(f)\n",
    "    return dict1\n",
    "    \n",
    "def load_data_to_paragraphs(file):\n",
    "    \"\"\" 将长文档分解成1000字以内短文档. \n",
    "    因为openai sentence embedding ada 002 8000 input token, 最大2000汉字\n",
    "    但是逼近2000后语义编码效果会下降\n",
    "    \"\"\"\n",
    "    with open(file, \"r\") as f:\n",
    "        data = f.read()\n",
    "    pattern1 = r'^.*?内容梗概: '\n",
    "    pattern2 = r' 友情链接：Gnews \\| Gclubs \\| Gfashion \\| himalaya exchange \\| gettr \\| 法治基金 \\| 新中国联邦辞典 \\| $'\n",
    "    data = re.sub(pattern1, \"\", data)\n",
    "    data = re.sub(pattern2, \"\", data)\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    txts = text_splitter.split_text(data)\n",
    "    return txts\n",
    "\n",
    "def sentence_embedding_batch(txts, id):\n",
    "    \"\"\"将list of text编码为sentence embedding 1538维\"\"\"\n",
    "    l1 = []\n",
    "    #embs = get_embeddings(txts, engine=\"text-embedding-ada-002\")\n",
    "    response = openai_client.embeddings.create(input = txts, model=\"text-embedding-ada-002\")\n",
    "    response = json.loads(response.json())[\"data\"]\n",
    "    embs = [x[\"embedding\"] for x in response]\n",
    "    for i, txt in enumerate(txts):\n",
    "        label = f\"{id}-{i}\"\n",
    "        emb = embs[i]\n",
    "        l1.append((label, txt, emb))\n",
    "    return l1\n",
    "\n",
    "def encoding_file(in_file, output_dir):\n",
    "    \"\"\"将文档.txt文件编码为同名 embedding文件\"\"\"\n",
    "    id = os.path.basename(in_file).split(\".\")[0]\n",
    "    out_file = os.path.join(output_dir, id+\".npz\")\n",
    "    txts = load_data_to_paragraphs(in_file)\n",
    "    packs = sentence_embedding_batch(txts, id)\n",
    "    serialized_data = pickle.dumps(packs)\n",
    "    compressed_data = gzip.compress(serialized_data)\n",
    "    with open(out_file, \"wb\") as file:\n",
    "        file.write(compressed_data)\n",
    "\n",
    "def encoding_files(input_dir = \"./txts/\", output_dir = \"./emb\"):\n",
    "    \"\"\"批量将文件夹下txt文件编码为同名 embedding文件，openai 3美元\"\"\"\n",
    "    files = [os.path.join(input_dir, x) for x in os.listdir(input_dir)]\n",
    "    if not os.path.isdir(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "    for i, in_file in enumerate(tqdm(files)):\n",
    "        encoding_file(in_file, output_dir)\n",
    "\n",
    "def decoding_file(file):\n",
    "    with open(file, \"rb\") as f:\n",
    "        compressed_data = f.read()\n",
    "    decompressed_data = gzip.decompress(compressed_data)\n",
    "    l1 = pickle.loads(decompressed_data)\n",
    "    return l1\n",
    "\n",
    "def build_faiss_index(embs):\n",
    "    import faiss\n",
    "    d = 1536\n",
    "    nlist = 100\n",
    "    index = faiss.IndexFlatIP(d)\n",
    "    #index = faiss.IndexIVFFlat(index, d, nlist)\n",
    "    index.train(embs)\n",
    "    index.add(embs)\n",
    "    return index\n",
    "    \n",
    "\n",
    "def build_veactor_search_index(folder=\"./emb\"):\n",
    "    files = [os.path.join(folder, x) for x in os.listdir(folder)]\n",
    "    dict1 = dict()\n",
    "    i = 0\n",
    "    embs = []\n",
    "    for file in tqdm(files):\n",
    "        l1 = decoding_file(file)\n",
    "        for idx, txt, emb in l1:\n",
    "            dict1[i] = {\"idx\": idx, \"txt\": txt, \"emb\": emb}\n",
    "            embs.append(emb)\n",
    "            i+=1\n",
    "    embs = np.vstack(embs)\n",
    "    embs /= np.linalg.norm(embs, ord=2, axis=-1, keepdims=True) + 1e-8\n",
    "    faiss_index = build_faiss_index(embs)\n",
    "    return embs, dict1, faiss_index\n",
    "\n",
    "def text_search(query, faiss_index, dict_emb, dict_title, k=3):\n",
    "    \"\"\" 每1000 token 250汉字 0.0001美元\"\"\"\n",
    "    if len(query)<10:\n",
    "        query = f\"这是一个关于{query}的句子\"\n",
    "    #emb_query = get_embedding(query, engine=\"text-embedding-ada-002\")\n",
    "    response = openai_client.embeddings.create(input=[query], model=\"text-embedding-ada-002\")\n",
    "    emb_query = json.loads(response.json())[\"data\"][0][\"embedding\"]\n",
    "    emb_query = np.array(emb_query).reshape((1, -1))\n",
    "    D, I = faiss_index.search(emb_query, k)\n",
    "    txts = []\n",
    "    for i in I[0]:\n",
    "        idx = dict_emb[i][\"idx\"]\n",
    "        idx0 = idx.split(\"-\")[0]\n",
    "        txt = dict_emb[i][\"txt\"]\n",
    "        title = dict_title[idx0]\n",
    "        txts += [(title, txt)]\n",
    "    return txts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c029e02b-378d-4450-b77c-b5fe7c3d9b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2866/2866 [00:05<00:00, 559.84it/s]\n"
     ]
    }
   ],
   "source": [
    "#download_documents()\n",
    "#encoding_files(input_dir = \"./txts/\", output_dir = \"./emb\")\n",
    "#extract_titles(input_dir=\"./txts/\", out_file=\"titles.json\")\n",
    "embs, dict_emb, faiss_index = build_veactor_search_index(folder=\"./emb\")\n",
    "dict_title = load_titles(file=\"titles.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "45c982ce-049a-4264-a8b3-68c3b312213b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' 郭文贵2022年10月23日直播 20221023_2 【中共伪二十大事件真相 】 ',\n",
       "  '李克强看着这个时候啊，大家你看到李克强从这个之前一直往前看，根本不敢侧看，此人怎么能当总理呢？！我曾经跟他比，跟你火来比，跟飞飞还接近过。我们在一起在相枕而眠七整天，又在一起一个屋子睡觉不超过--最起码得40个夜晚，是吧。我们跟你们没有睡过，一个人睡过一整晚觉。就这个人，我从第一天，我就说这个家伙我看不起他，我就真的看不起他。我今天我真的是......此人不是人也，也就甭说是男人了。 你看啊，你看这个可怜，“我就想说几句，”你看到后面的人，你看到王毅，你看到了解放军将领，你想想这些，中国这些还有一点良知吗，中国人？！黑道儿都不会这样。你看看，你看看这个汪洋，那个汪洋在和王岐山，一会儿要找到另一个角度视频，小铁。他的动作是最大的，就汪洋和韩正和王岐山是这里最想有动作的。你可以看到几次想起身，眼睛很一直往下看，一直有没有人说话，有没有人说句话呀，都想等着别人开口。 嗯，就没有像当年罗马尼亚齐奥塞斯库演讲的时候，有个角落里喊，“打倒齐奥塞斯库”，旁边就是“打倒齐奥塞斯库”，完了！齐奥塞斯库被枪毙了。就没有这一嗓子，悲哀！！强大的中国人民实在太强大了，我看完这个以后，我在想真的这个灭共的事情，咱要不要灭共，真的，还灭它干啥呀，就让共产党那儿多待几年，就这帮王八蛋互相杀去吧。 你看看这种德性，你觉得哪个人配当我们的同类，同族？！我们感到羞耻不羞耻？！你再看看海外的所有的欺民贼，还有伪类们，就在美国，所有人把胡锦涛说成是有病，他今天的身体状态比他退出还好，他也没有帕金斯症，他脑子倍儿清楚，而且能写，我很惊讶。 我昨天才知道，我说，“他到底写的啥？”他说他写的：‘他是支持习近平在特殊情况下连任第三期，但下不为例，最后一期。然后要继续搞党内民主，反对隔离清零，对老百姓太惨了，继续经济改革开放，然后坚决不能打台湾，对国家统一最好的办法就不要打台湾，承诺不打台湾。’你说这个脑子是清楚的，是吧。 这种情况下，他自己写，弄了一页纸，他是准备好，今天你选完我，我讲几句话，习近平也答应他了。但是他到这里一看你这个名字了，他就不愿意了，他要抢习的麦克风，麦克风，他就推他，推他的时候，这时候习就就把孔绍逊找来，保镖找来，给我架出去。 他俩来了就要骗他，“我让你站前面演讲去，”就给绑架走。旁边的王沪宁，栗战书执行了这个惨无人道的踩脚，拖走，没收文件。韩正和汪洋和王岐山跃跃欲试，但最终没敢出手。请。'),\n",
       " (' 郭文贵2022年2月27日直播 20220227_1俄乌战争预测台海；普京嚣张中共角色；世界经济金融市场；台湾沦陷如何应对 ',\n",
       "  '这不说战争结果，别说被干掉还是干不干掉，先别说，剩下就两个奇怪的结局：一，和解了，大家都回去，它也要面对这个结局；二，它放核武器，或者是乌克兰和美国在哪方面再支持它，把它给整怎么着了，然后它再来个狠的，什么“切尔诺贝利泄漏”或者什么“普京被那边被做掉”，这种滑稽的结局一定会出现的，突然间，会突然间。一方被干掉，一方停战，被改变，或哪个人再出事，但是俄罗斯的命运不会改变的，就是这结局了。 那共产党的结局是什么你告诉我？从今天起，一会儿你们谈谈，到今天为止，共产党会面临什么样的结局啊？咱一会儿说，谢谢好好先生！你第一天今天上来就告诉我，你在美国把护照弄掉了回去，你这家伙，我见了你我非踹你两脚不行，你个傻子，被他们给骗，咱要报仇！谢谢好好先生！ 好好先生：好的，谢谢七哥！我们一定会报仇的！那媒体战这一边也是战争，我们一定会智取。好的，谢谢，交给主持人。 卡丽熙：谢谢七哥！七哥一席话让我们知道、更加知道这个战略的智慧和信息时代的战争。其实我还想说一句，我们好好先生虽然一开始被在美国放弃了，但是我们片头的这个歌曲是我们好好先生唱的，他是一个多才多艺的年轻人。 郭文贵先生：是吗？特别棒！弹得比我好，弹的比我好。你现在是关键以乐灭共，加入到唐平的队伍里面去，好好先生，赶快找唐平，太关键了，谢谢了。 卡丽熙：好，七哥，我们现在是继续提问题还是让我们的视频组跟大家分享PPT？我们七哥累了，要不要喝点水、喝点茶 郭文贵先生：可以呀，可以呀，PPT，分享PPT。 卡丽熙：好，请我们的导播请出我们的Eric给大家分享我们的今天的PPT。 郭文贵先生：又是Eric来了（注：笑）Eric我的兄弟，太可爱了，超级猛男。 1:00:07Eric分享PPT《俄乌谈判破裂 世界进入危局》 卡丽熙：非常感谢我们的Eric。刚才我们的七哥跟我们分享了很多很多的信息时代的战略智慧。七哥来了，好，还给七哥。我们刚才Eric分享了我们的PPT，七哥，有什么跟大家要分析的吗？ 1:03:22 Eric很优秀，男人有才华就可爱；女人善良就漂亮'),\n",
       " (' 郭文贵2022年5月17日直播 20220517_1直播乱聊 ',\n",
       "  '但是王岐山就选择李克强那边，应该是没想到吧。王岐山和曾全走到李克强那边去了，这是江和曾和这个共青团，绝对是水火不容啊是吧？李克强是胡锦涛的人啊，而且习也是恨这个李克强，但你能想到吗现在？王岐山、曾庆红通通地走到李克强那去 就连朱镕基，当年朱镕基当时当总理的时候，李克强只要一说话，只要一说话，朱镕基就骂他。就朱镕基欺负他，欺负到了要死的程度。现在朱镕基也投靠李克强了，你想想这是什么概念啊？兄弟姐妹们。 所以说这个问题，它已经不是政治的问题啦，它是一个生死的选择。大家想想，就是抓个稻草，但是稻草也是草，我觉得李克强连个稻草都不算。我觉得李克强连稻草都不算，现在共产党抓了一个连稻草都不算的李克强。 （看留言）李克强的接任可能性有多大？可能性有多大是吧？没什么可能性我觉得。谢谢Rachel！ 小王子：七哥那您说就现在整个20大前夕王岐山还有朱镕基、曾庆红他们整个投靠李克强，这个反映了党内现在政治斗争怎么样的一个情况？ 郭文贵先生：我觉得李克强是要绝对玩政治上绝不输习近平的，这我绝对有说话权力。但是李克强现在是一个没有选择下的一个这些人的选择。但是我觉得到最后的时候，可能估计都不会让李克强上去，如果有那天的话——习被灭的话，我会觉得李克强他腿没迈出去就给灭了就。 我觉得现在已经没有什么”上海帮“啦，现在严格讲曾家是吧，还有这个朱镕基家，所有这些人，谢谢！（工作人员取走水杯）所有这些人都是在保命，谁管你什么共产党不共产党。如果说现在说把共产党贬成猪党、狗党他也愿意，只要能保命，就是保命嘛。现在跟七哥当年说的一样保命是吧？保财、报仇，这都是所有人的心里想法，跟共产党已经没有半毛钱关系了。 但是人家会利用共产党是吧，利用这个组织和权力，就是抢的这个权力嘛。我觉得李克强是被所有人利用的一个人，但是最后我不相信他，有机会，很少的机会，很少。李克强强硬一下，李克强根本没有强硬，李克强做最后的垂死挣扎。 习绝对是有高人在帮他运作，就让他干。 郭文贵先生：好，咱今天试直播试到这啊，现在的感觉怎么样？我觉得很好，就那天我们直播的时候你看，现在已经是黑了吗？ 小王子：看一下有没有反光主——镜头？ 工作人员：稍稍有些。 郭文贵先生：如果那天，现在是几点？七点多吗？八点了都，那就太没问题啦！你干嘛要搞，就这样就行了嘛。 小王子：我们可以一会儿继续，七哥您忙先走，我们可以继续直播到晚上。')]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_query = \"李克强的结局\"\n",
    "txts_retrival = text_search(txt_query, faiss_index, dict_emb, dict_title, k=3) #请求10000次API成本1美金\n",
    "txts_retrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ee45a8c9-ad4a-462d-98d1-1323799d9f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "根据参考文本中的内容，摘要如下：\n",
      "\n",
      "1. 文本中提到了关于辉瑞疫苗的不良反应和副作用，包\n",
      "[(' 郭文贵2021年10月29日直播 20211029_1格芯在美国上市的重大意义和其未来价值，格芯与数字货币紧密相连；喜币周一上市会带来什么样的改变；房地产会在明年5-7月爆雷，是中共制造的最大的噩梦 ', '（新冠疫苗）有许多不良反应，很多副作用包括肌肉疼痛、胸痛、呼吸困难，我们看到肺部症状甚至肺炎。 主持人：心脏炎症？ 嘉宾：心脏炎症、肺部炎症。 主持人：有时候会很致命。 嘉宾：会的。 嘉宾：有趣的是我们有4个孩子因为心肌炎来到诊所。 主持人：他们打疫苗了吗？ 嘉宾：都打了疫苗，12-16岁已经批准要求接种，我们那里有很多孩子为了回到运动场，所以他们开始接种疫苗。我们有4例心肌炎。 主持人：好， 那现在的问题是这个年龄段通常会发生心肌炎吗？你是每年都看到几例呢？还是你将其归咎于疫苗？ 嘉宾：在我将近20年的职业生涯中直到今年我才在青少年或儿童中看到心肌炎的病例。 主持人：你现在看到4例。 嘉宾：是的今年看到4例。 ● 10:43视频六：疫苗接种者讲述自己接种后各种副作用情况 我叫Kristy Dobbs 我是一名洗牙师，妻子和四个孩子的母亲，我支持科学我信任好的医疗。我在2021年1月18日 接受了第一剂也是唯一一剂 辉瑞公司的新冠疫苗，当时我在指定接种疫苗的诊所就立即出现了反应，刚接种后我的最初反应是在左臂上有一种刺痛的感觉，感觉像有水在我的手臂内滴落，我还没来得及坐下休息，一些反应就突然同时出现了，我无法呼吸 感觉很热，脉搏呼吸和心率都增加了，血压读数也高到了中风的程度，在注射辉瑞疫苗后的两天我的症状包括手臂酸痛、疲劳、淋巴结肿大和头痛，这些都是我预料到的，也是知情同意中有提到的正常副作用，然而在接种后的第三天疫苗的药效开始蹂躏我的身体，我的左肩胛区 出现了尖锐的刺痛以及我的左臂和左手出现了麻痹感和颤抖，到了第四天 我出现了全身震颤和麻痹。 以及体内像过电般的抽搐，感觉到极度疲劳 脑雾 肌肉疼痛和虚弱，无法入睡，出现多种自主神经功能紊乱，我有超过22种不同的症状，已经困扰我九个多月，至今我已经看了超过15个不同的医疗机构和专家早在3月份 我甚至与Safavi医生 （就职于于美国国立卫生研究院）进行了一次远程医疗访问，我被明确告知不要给我的孩子接种疫苗，我已经把我的血样送到了美国国立卫生研究院以及多个著名的大学和私人研究人员那里研究。 我的疫苗伤害已报告给辉瑞公司，VAERS、CDC 、FDA、 NIH和其他著名研究机构、疫苗受伤者与CDC和FDA的高级官员之间存在信息交换和会议，包括Rochelle Walensky （cdc主任）Peter Marks'), (' 郭文贵2021年9月7日直播 20210907_1政治与艺术的关系：拍卖行背后都是军方的势力；所有的古董字画都是政治情报，都是洗钱和行贿；马明哲对台湾的渗透腐败都是核弹级的；最大的艺术品保险就是马明哲。解读黑天鹅事件，毛泽 ', '：九个月之后，疫苗引发的副作用会让很多接种过疫苗的人感到后悔 主持人：九个月之后，很多人会对接种过中共病毒疫苗，感到悔恨，因为他们看到了疫苗引发的副作用，FDA的黑框警告，心肌炎，诸如此类，是否有方案也能够帮到这些人呢？ 大胡子医生：是的，它叫做常识，你身体内有个炸弹，很抱歉，但那是你自己放进去的炸弹。所以说第一件事是不要造更多的炸弹，不要再打更多的疫苗，然后你要知道，你体内炸弹的引爆点是什么？引爆点是另一次的病毒感染。病毒和体内相应的抗体产生反应，就可能导致抗体依赖增强，该领域的世界专家在大声疾呼，因为这会导致种族灭绝，所以要说处理他的方法。无论你是否只有十岁，只要已经接种了疫苗，你就有和95岁的疗养院病人一样的风险，而你需要做的是采取（我的）高风险预防措施，以及早期的治疗，以便你不会再次被类似中共病毒的病毒感染。即便你体内有一个炸弹，但并不意味着它一定会爆炸，你必须远离引爆点。我们在谈论并关注的是生死问题，你知道，让我来定义成功，不死便是成功，不要最后进医院上呼吸机，这就是我们衡量成功的标准。 视频7 ：积极治疗很重要 医生：很高兴见到你，教练！ 病人：早上好，医生！ 医生：你感染了COVID-19，何时感染的？ 病人：星期三，十一号。 医生：你有何症状？ 病人：我发烧了，感觉很虚弱，所以我去进行了检测。 医生：然后你就联系我进行治疗了？ 病人：是的，当天下午我马上就去了，我得到了您给的配套治疗方案，鸡尾酒疗法，然后我就开始服药。 医生：药都很对路吧？ 病人：是的。 医生：所有的药……氢氯喹、伊维菌素、锌、多西环素、维生素D和阿司匹林。 病人：没错儿。 医生：太好了！你什么时候注意到治疗产生效果的？ 病人：最贴切的说法是，假如10是我最糟糕的情况，服药后，我大概处于2.5的水平。 医生：当你（服药后）从10降到了2.5。 病人：没错，我经历了整个过程（后来）降到了大约2.5，并且从未失去味觉或嗅觉，我当时很虚弱，我感到浑身乏力，疲惫不堪，但情况慢慢开始发生变化。 医生：好极了，因此你的结果确实很好。 病人：是的 医生：你没有接种过疫苗吧？ 病人：没有，我的妻子也没有。她的情况跟我相同。 医生：她接受我们的治疗了嘛？ 病人：是的，她马上按照您的治疗方案进行了治疗。其实我第一个晚上我就告诉她了然后第二天她开始服药。 医生：太好了，她康复的很好。'), (' 郭文贵2021年9月17日直播 20210917_1恒大就是旁氏骗局，中国有2.5亿人卷入，这是国家金融灾难，世界灾难；不打疫苗就是财富；SEC和解协议和纽约州总检查长的保证书的重大意义，中共司法超限战彻底失败，报假案的一定会得到严 ', '这个是在施打完毒疫苗之后，副作用是白血病。打疫苗之后，三天就发现得了急性淋巴白血病，才二十岁而已。也有造成无法勃起，但是无法和谐也有可能是一个假新闻，还要确认一下。这也是几篇报道，就是说疫苗确诊之后，造成这些白血病的一个确诊。好，下一页。 这个是就各种梗，现在是脑梗，还有心梗等等，还有各种梗的一个死亡。好下一页。 最后这一页是在中共国的科学网站上面确认的，还是在中科院的武汉病毒所。毒疫苗其实还在第一期、第二期的临床测试，其实根本还没结束。结束的时间都是在二零二一年的十一月十日。所以说，代表大家现在接种疫苗，全部都是白老鼠的阶段。好，谢谢！ PPT2：目前国际上的疫苗后遗症 小福利：好，我们接着给大家介绍一下，目前国际上的疫苗后遗症。 首先是意大利政府在2021年10月15日开始，每个雇员都必须出示疫苗接种或者是检测证明，所谓的绿色通行证。否则五天后会被停职，而且没有工资。 小Seven：对，报道上没有区分是否是政府的雇员，还是私人的雇员。 小福利：对，上方的二维码，战友们都可以去看报导的原出处。另外意大利，一位十六岁的女孩在接种疫苗之后，十六个小时之后死亡。这也是官方的报道，大家都可以去看原文链接。另外意大利和法国反对疫苗、CCP病毒疫苗护照，上街的示威活动。还有法国另外的一些上街的活动，都是选择自由，反对强制接种疫苗的活动。 最后是世卫组织独家的采访，谈到辉瑞疫苗接种之后，出现的神经系统。出现神经系统症状的十八岁少年说，我只想让我的生活回来。这就是很年轻…… 小Seven：不是世卫组织，是一个儿童健康的卫生组织，跟世卫组织没关系。 小福利：这是儿童健康卫士组织独家的一个采访，这是十八岁的少年。 另外澳大利亚目前是限制使用伊维菌素。卫生部2021年9月10日，为COVID-19也就是ccp病毒，开具伊维菌素处方的新限制。 最后是德国保守党派AFD的领袖在报道中称，采取行动，反对任何对未接种疫苗者的歧视。好，我们的PPT就到这里，谢谢。 小Seven：先告一段落吧！我们后面还有Nick准备了。 小福利：对，Nick准备。 更多战友染病的新消息 郭文贵先生：你看，就在我说的时候，你们在群里也看到了—王雪冰老班长发的。咱们有战友，在荷兰的有家人，可能已经过世了—急需羟氯喹，还有伊维菌素。现在我们荷兰的战友，已经联系上。就在我们刚才说的时候，到现在就发生这事，又有新的。')]\n"
     ]
    }
   ],
   "source": [
    "def RAG_chatbot(txt_query, txts_retrival):\n",
    "    \"\"\"\n",
    "    请求500次API成本1美金左右\n",
    "    遇到与chatgpt观念不符合的文本时效果仍然不好，甚至会被掐断。\n",
    "    需要试验其他本地化开源LLM\n",
    "    \"\"\"\n",
    "    prompt = \"\\n\\n\".join([f\"标题：{title}\\n 正文：{txt}\" for title, txt in txts_retrival])\n",
    "    prompt = f\"先摘要并总结参考文本，再解答这个问题{txt_query} 以下是参考文本\\n\\n{txts_retrival}\"\n",
    "    \n",
    "    response = openai_client.chat.completions.create(model=\"gpt-3.5-turbo\",\n",
    "      messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "    txt_response = json.loads(response.json())[\"choices\"][0][\"message\"][\"content\"]\n",
    "    return txt_response\n",
    "\n",
    "txt_query = \"接种辉瑞疫苗有哪些后果？\"\n",
    "txts_retrival = text_search(txt_query, faiss_index, dict_emb, dict_title, k=3)\n",
    "txt_response = RAG_chatbot(txt_query, txts_retrival)\n",
    "print(txt_response)\n",
    "print(txts_retrival)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f9f375c-812e-4209-96d5-45e266808a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: [[0.99999994 0.9173957  0.90672827 0.9045879  0.9038532  0.897203\n",
      "  0.89675575 0.8966185  0.89628506 0.89613855]]\n",
      "Indices: [[    0     1  5983 21589 24700 29149 19581 18945 14504 27710]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9f412e1c-307b-44c4-a0f4-cb4e58f52e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.0.334'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langchain\n",
    "langchain.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a122cabb-2073-4b6d-bfb9-2eb17f9dfe25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
